{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions() \n",
    "options.add_argument('--headless') \n",
    "options.add_argument('--no-sandbox') \n",
    "options.add_argument('--disable-dev-shm-usage') \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from urllib.parse import quote\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동아일보도 San Francisco Chronicle 과 비슷하게 url에 날짜설정이 안되어서, \n",
    "# 날짜순서대로 정렬한후, if문을 돌려서 중간에 코드를 break 하는 형식으로 작성했습니다.\n",
    "# San Francisco Chronicle 과 같게 chromedriver를 사용하면 시간이 너무 오래걸려(다량의 기사필요)\n",
    "# urllib를 사용하였습니다. 또한, 진행중 DDOS공격으로 의심되어 IP밴당하는 사례가 생겨서,\n",
    "# 추가적으로 밑에서 코드를 수정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def start_crawling(keyword,START_DATE,END_DATE,for_DDOS_pagenum): # 시작하는 함수입니다. keyword만 url에 들어가있고, 날짜는 추가적인 코드를 통해 거를 예정입니다.\n",
    "    URL = f'ttps://www.donga.com/news/search?p=1&query={keyword}&check_news=1&more=1&sorting=1&search_date=1&v1=&v2=&range=1'\n",
    "    start_date = datetime.datetime.strptime(START_DATE,'%Y-%m-%d')\n",
    "    end_date = datetime.datetime.strptime(END_DATE,'%Y-%m-%d')\n",
    "    get_link_from_news_title(URL,start_date,end_date,for_DDOS_pagenum)\n",
    "            \n",
    "def get_link_from_news_title(hURL,START_DATE,END_DATE,for_DDOS_pagenum):\n",
    "    firstURL = 'h' + hURL # 경향과 마찬가지로 하이퍼링크 이슈에관한 디버깅입니다.\n",
    "    req = urllib.request.Request(firstURL, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'})        \n",
    "    source_code_from_url = urllib.request.urlopen(req)\n",
    "    firstsoup = BeautifulSoup(source_code_from_url, 'lxml', from_encoding='utf-8') # 첫 화면 soup 따주고\n",
    "    num1 = firstsoup.select('#content > div.searchContWrap > div.searchCont > h2 > span:nth-child(1)')[0].get_text()\n",
    "    num2 = num1.replace('(총 ', '')\n",
    "    num = int(num2.replace(' 건 검색)', ''))\n",
    "    page_num = int(num /15) +1 # 경향과 마찬가지로 page_num을 구해줍니다.\n",
    "    \n",
    "    Flag = True # for문 break를 위한 Flag입니다.\n",
    "    pagenum1 = for_DDOS_pagenum*100 # DDOS로 의심받기때문에, timesleep을 위해 추가하였습니다.\n",
    "    pagenum2 = (for_DDOS_pagenum*100) +100 # 100page마다 150초씩 쉬어줍니다.\n",
    "    if pagenum2 > page_num: # 또한 마지막에서 range에러가 날 수 있기때문에\n",
    "        pagenum3 = page_num # if문으로 조건을 지정해서 range의 최댓값이 page_num보다 클수 없게 지정했습니다.\n",
    "    else:\n",
    "        pagenum3 = pagenum2\n",
    "        DDOS = False # 실행할때 while True: 문을 쓰기때문에 그것을 break해줄 DDOS 플래그입니다.\n",
    "        \n",
    "    for j in range(pagenum1,pagenum3): # 0~100, 100~200, 등등 올라갑니다. 마지막엔 700~777(page_num)\n",
    "        article_number = (j*15) +1 # 페이지당 15개입니다.\n",
    "        URL = f'ttps://www.donga.com/news/search?p={article_number}&query={keyword}&check_news=1&more=1&sorting=1&search_date=1&v1=&v2=&range=1' \n",
    "        # 특이하게 url에서 p= 다음에 페이지 수가 아닌 기사갯수가 들어가더라구요 15 * i +1 의 형식입니다.\n",
    "        req = urllib.request.Request('h'+URL, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'})        \n",
    "        source_code_from_url = urllib.request.urlopen(req)\n",
    "        soup = BeautifulSoup(source_code_from_url, 'lxml', from_encoding='utf-8') # soup 따주고\n",
    "        for i in range(0,len(soup.select('p.tit'))):        \n",
    "            date1 = soup.select(f'#content > div.searchContWrap > div.searchCont > div:nth-child({i+2}) > div.t > p.tit > span')[0]\n",
    "            date2 = date1.get_text()[:10] # date 따줍니다.\n",
    "            try: # 가끔 date를 못가져 오는 경우가있는데, 이것은 바로 전의 기사의 날짜로 대체하는 try except문입니다.\n",
    "                 # 날짜순으로 정렬을 했기때문에, 날짜가 변하는일은 거의 없을겁니다. (에러도 정말 가끔 일어납니다.)\n",
    "                date = datetime.datetime.strptime(date2,'%Y-%m-%d')\n",
    "            except:\n",
    "                date = lastdate\n",
    "            lastdate = date            \n",
    "            if START_DATE >= date: # 날짜순으로 정렬된 기사를 거르는 if문입니다.\n",
    "                if date >= END_DATE: \n",
    "                    str_date = str(date)[:10] # date를 str로 변환해주고 년,월,일만 남기고 잘라줍니다.\n",
    "                    title_name = soup.select(f'#content > div.searchContWrap > div.searchCont > div:nth-child({i+2}) > div.t > p.tit > a:nth-child(1)')[0].get_text()\n",
    "                    # 기사제목\n",
    "                    title_link = soup.select(f'#content > div.searchContWrap > div.searchCont > div:nth-child({i+2}) > div.t > p.tit > a:nth-child(1)')[0]['href']\n",
    "                    # 기사링크 따준후\n",
    "                    TITLE_OF_ARTICLE.append(title_name) \n",
    "                    DATE_OF_ARTICLE.append(str_date)\n",
    "                    LINK_OF_ARTICLE.append(title_link)\n",
    "                    # 어펜드 해준후에 get_text로 넘겨줍니다\n",
    "                    get_text(title_link)\n",
    "                else:\n",
    "                    Flag = False # for문의 break를 위한 Flag입니다.\n",
    "                    break # 2010.01.01 이후 날짜는 가져올필요가없기에 break 해줍니다.\n",
    "        \n",
    "        print(f'{j+1}페이지 완료') \n",
    "        \n",
    "        if Flag == False:\n",
    "            break # 2010.01.01 이후 날짜는 가져올필요가없기에 break 해줍니다.\n",
    "            \n",
    "def get_text(link):\n",
    "    req = urllib.request.Request(link, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'})        \n",
    "    source_code_from_url = urllib.request.urlopen(req)\n",
    "    soup = BeautifulSoup(source_code_from_url, 'lxml', from_encoding='utf-8')\n",
    "    # 링크 받아서 soup 따줍니다\n",
    "    \n",
    "    # 전처리 과정인데, 동아일보는 기사 본문안에 부제목, 사진설명, 관련기사, 등등이 모여있어서 \n",
    "    # 만약 있으면, 제거해주는 코드입니다.\n",
    "    text = str(soup.find_all(\"div\", {\"class\": \"article_txt\"})[0].get_text())# 전체 기사를 모아주고\n",
    "    \n",
    "    text1 = soup.find_all(\"div\", {\"class\": \"articlePhotoC\"}) # 전체 기사중에서 사진설명을 모두 없애줍니다.\n",
    "    for i in text1: #사진설명이 없을경우 text1이 빈 리스트이기때문에 실행되지 않습니다.\n",
    "        x = str(i.get_text())\n",
    "        text = text.replace(f'{x}', '')\n",
    "    \n",
    "    try: #관련기사가 없을경우 에러가 뜨기때문에 try except문 사용해서 관련기사가 없으면 실행 안됩니다.\n",
    "        text2 = str(soup.find_all(\"div\", {\"class\": \"article_relation\"})[0].get_text()) # 관련기사를 없애줍니다\n",
    "        text = text.replace(f'{text2}', '')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try: #마찬가지로 부제목 없애주는 함수입니다.\n",
    "        text3 = soup.find_all(\"strong\", {\"sub_title\"})[0].get_text() # 부제목 없애줍니다.\n",
    "        text = text.replace(f'{text3}', '')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    text = text.replace('\\n', '.') # 불필요한 Enter키는 우선 \".\"으로 바꿔줍니다.(후에 전처리)\n",
    "    \n",
    "    # 여기부턴 기사 본문 뒤에서 기자 이름등 쓸모없는 부분을 전처리 하는 부분인데, \n",
    "    # 이러한 순서대로 전처리를 하게되면 거의 대부분 없어지는것을 확인하였습니다.\n",
    "    # find함수는 찾지못하면 -1이 return되기때문에, -1이 아니면 indexing 된것으로 보고\n",
    "    # 전처리 진행하였습니다.\n",
    "    # 다수를 위해 소수의 기사는 희생되었을 수도 있습니다....(TT)\n",
    "    \n",
    "    q = text.find('동아닷컴 기자')\n",
    "    # 기사 본문에서 '동아닷컴 기자' 를 찾아서 그앞에 -4만큼 \n",
    "    # /여기/(홍길동 동아닷컴 기자) 부터 뒤를 전부 없애주는 함수입니다.\n",
    "    if q != -1:\n",
    "        text = text[:q-4]\n",
    "\n",
    "    m = text.find('동아닷컴')\n",
    "    # 마찬가지로 동아닷컴이 있으면 그 뒤로는 전부 없애줍니다.\n",
    "    # ex) 기사본문. /여기/(동아닷컴) 홍길동 기자\n",
    "    \n",
    "    # 거의 대부분의 기사가 동아닷컴 기자, 동아닷컴에서 전처리가 완료됩니다. 이후(기자, (서울=) 등은 앞의 전처리 과정에서 삭제됩니다.)\n",
    "    # 간혹 삭제되지 않는 기사가 있기에 추가하였습니다.\n",
    "    \n",
    "    #마찬가지로 이러한 단어가 있으면 뒤에는 전부 제거해줍니다.\n",
    "    if k != -1:\n",
    "        text = text[:k-4]\n",
    "\n",
    "    l = text.find('[서울=')\n",
    "    if l != -1:\n",
    "        text = text[:l]\n",
    "\n",
    "    o = text.find('(서울=')\n",
    "    if o != -1:\n",
    "        text = text[:o]\n",
    "\n",
    "    p = text.find('도쿄=')\n",
    "    if p != -1:\n",
    "        text = text[:p]    \n",
    "\n",
    "    n = text.find('창닫기')\n",
    "    if n != -1:\n",
    "        text = text[:n]\n",
    "    \n",
    "    # 마지막으로 희생당한 기사를 위한 코드인데, 간혹 기사의 길이가 너무 짧거나, 기사가 아니거나, 전처리과정에서 희생당한경우( ex)동아닷컴 )\n",
    "    # 기사의 길이가 현저하게 낮은데 이러한 기사를 ERROR로 append 해주는 함수입니다.\n",
    "    if len(text) > 100:\n",
    "        CONTENT_OF_ARTICLES.append(text)\n",
    "    else:\n",
    "        CONTENT_OF_ARTICLES.append(\"ERROR\")   \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1페이지 완료\n",
      "2페이지 완료\n",
      "3페이지 완료\n",
      "4페이지 완료\n",
      "5페이지 완료\n",
      "6페이지 완료\n",
      "7페이지 완료\n",
      "8페이지 완료\n",
      "9페이지 완료\n",
      "10페이지 완료\n",
      "11페이지 완료\n",
      "12페이지 완료\n",
      "13페이지 완료\n",
      "14페이지 완료\n",
      "15페이지 완료\n",
      "16페이지 완료\n",
      "17페이지 완료\n",
      "18페이지 완료\n",
      "19페이지 완료\n",
      "20페이지 완료\n",
      "21페이지 완료\n",
      "22페이지 완료\n",
      "23페이지 완료\n",
      "24페이지 완료\n",
      "25페이지 완료\n",
      "26페이지 완료\n",
      "27페이지 완료\n",
      "28페이지 완료\n",
      "29페이지 완료\n",
      "30페이지 완료\n",
      "31페이지 완료\n",
      "32페이지 완료\n",
      "33페이지 완료\n",
      "34페이지 완료\n",
      "35페이지 완료\n",
      "36페이지 완료\n",
      "37페이지 완료\n",
      "38페이지 완료\n",
      "39페이지 완료\n",
      "40페이지 완료\n",
      "41페이지 완료\n",
      "42페이지 완료\n",
      "43페이지 완료\n",
      "44페이지 완료\n",
      "45페이지 완료\n",
      "46페이지 완료\n",
      "47페이지 완료\n",
      "48페이지 완료\n",
      "49페이지 완료\n",
      "50페이지 완료\n",
      "51페이지 완료\n",
      "52페이지 완료\n",
      "53페이지 완료\n",
      "54페이지 완료\n",
      "55페이지 완료\n",
      "56페이지 완료\n",
      "57페이지 완료\n",
      "58페이지 완료\n",
      "59페이지 완료\n",
      "60페이지 완료\n",
      "61페이지 완료\n",
      "62페이지 완료\n",
      "63페이지 완료\n",
      "64페이지 완료\n",
      "65페이지 완료\n",
      "66페이지 완료\n",
      "67페이지 완료\n",
      "68페이지 완료\n",
      "69페이지 완료\n",
      "70페이지 완료\n",
      "71페이지 완료\n",
      "72페이지 완료\n",
      "73페이지 완료\n",
      "74페이지 완료\n",
      "75페이지 완료\n",
      "76페이지 완료\n",
      "77페이지 완료\n",
      "78페이지 완료\n",
      "79페이지 완료\n",
      "80페이지 완료\n",
      "81페이지 완료\n",
      "82페이지 완료\n",
      "83페이지 완료\n",
      "84페이지 완료\n",
      "85페이지 완료\n",
      "86페이지 완료\n",
      "87페이지 완료\n",
      "88페이지 완료\n",
      "89페이지 완료\n",
      "90페이지 완료\n",
      "91페이지 완료\n",
      "92페이지 완료\n",
      "93페이지 완료\n",
      "94페이지 완료\n",
      "95페이지 완료\n",
      "96페이지 완료\n",
      "97페이지 완료\n",
      "98페이지 완료\n",
      "99페이지 완료\n",
      "100페이지 완료\n",
      "쉬는중입니다, DDOS차단 방지\n",
      "101페이지 완료\n",
      "102페이지 완료\n",
      "103페이지 완료\n",
      "104페이지 완료\n",
      "105페이지 완료\n",
      "106페이지 완료\n",
      "107페이지 완료\n",
      "108페이지 완료\n",
      "109페이지 완료\n",
      "110페이지 완료\n",
      "111페이지 완료\n",
      "112페이지 완료\n",
      "113페이지 완료\n",
      "114페이지 완료\n",
      "115페이지 완료\n",
      "116페이지 완료\n",
      "117페이지 완료\n",
      "118페이지 완료\n",
      "119페이지 완료\n",
      "120페이지 완료\n",
      "121페이지 완료\n",
      "122페이지 완료\n",
      "123페이지 완료\n",
      "124페이지 완료\n",
      "125페이지 완료\n",
      "126페이지 완료\n",
      "127페이지 완료\n",
      "128페이지 완료\n",
      "129페이지 완료\n",
      "130페이지 완료\n",
      "131페이지 완료\n",
      "132페이지 완료\n",
      "133페이지 완료\n",
      "134페이지 완료\n",
      "135페이지 완료\n",
      "136페이지 완료\n",
      "137페이지 완료\n",
      "138페이지 완료\n",
      "139페이지 완료\n",
      "140페이지 완료\n",
      "141페이지 완료\n",
      "142페이지 완료\n",
      "143페이지 완료\n",
      "144페이지 완료\n",
      "145페이지 완료\n",
      "146페이지 완료\n",
      "147페이지 완료\n",
      "148페이지 완료\n",
      "149페이지 완료\n",
      "150페이지 완료\n",
      "151페이지 완료\n",
      "152페이지 완료\n",
      "153페이지 완료\n",
      "154페이지 완료\n",
      "155페이지 완료\n",
      "156페이지 완료\n",
      "157페이지 완료\n",
      "158페이지 완료\n",
      "159페이지 완료\n",
      "160페이지 완료\n",
      "161페이지 완료\n",
      "162페이지 완료\n",
      "163페이지 완료\n",
      "164페이지 완료\n",
      "165페이지 완료\n",
      "166페이지 완료\n",
      "167페이지 완료\n",
      "168페이지 완료\n",
      "169페이지 완료\n",
      "170페이지 완료\n",
      "171페이지 완료\n",
      "172페이지 완료\n",
      "173페이지 완료\n",
      "174페이지 완료\n",
      "175페이지 완료\n",
      "176페이지 완료\n",
      "177페이지 완료\n",
      "178페이지 완료\n",
      "179페이지 완료\n",
      "180페이지 완료\n",
      "181페이지 완료\n",
      "182페이지 완료\n",
      "183페이지 완료\n",
      "184페이지 완료\n",
      "185페이지 완료\n",
      "186페이지 완료\n",
      "187페이지 완료\n",
      "188페이지 완료\n",
      "189페이지 완료\n",
      "190페이지 완료\n",
      "191페이지 완료\n",
      "192페이지 완료\n",
      "193페이지 완료\n",
      "194페이지 완료\n",
      "195페이지 완료\n",
      "196페이지 완료\n",
      "197페이지 완료\n",
      "198페이지 완료\n",
      "199페이지 완료\n",
      "200페이지 완료\n",
      "쉬는중입니다, DDOS차단 방지\n",
      "201페이지 완료\n",
      "202페이지 완료\n",
      "203페이지 완료\n",
      "204페이지 완료\n",
      "205페이지 완료\n",
      "206페이지 완료\n",
      "207페이지 완료\n",
      "208페이지 완료\n",
      "209페이지 완료\n",
      "210페이지 완료\n",
      "211페이지 완료\n",
      "212페이지 완료\n",
      "213페이지 완료\n",
      "214페이지 완료\n",
      "215페이지 완료\n",
      "216페이지 완료\n",
      "217페이지 완료\n",
      "218페이지 완료\n",
      "219페이지 완료\n",
      "220페이지 완료\n",
      "221페이지 완료\n",
      "222페이지 완료\n",
      "223페이지 완료\n",
      "224페이지 완료\n",
      "225페이지 완료\n",
      "226페이지 완료\n",
      "227페이지 완료\n",
      "228페이지 완료\n",
      "229페이지 완료\n",
      "230페이지 완료\n",
      "231페이지 완료\n",
      "232페이지 완료\n",
      "233페이지 완료\n",
      "234페이지 완료\n",
      "235페이지 완료\n",
      "236페이지 완료\n",
      "237페이지 완료\n",
      "238페이지 완료\n",
      "239페이지 완료\n",
      "240페이지 완료\n",
      "241페이지 완료\n",
      "242페이지 완료\n",
      "243페이지 완료\n",
      "244페이지 완료\n",
      "245페이지 완료\n",
      "246페이지 완료\n",
      "247페이지 완료\n",
      "248페이지 완료\n",
      "249페이지 완료\n",
      "250페이지 완료\n",
      "251페이지 완료\n",
      "252페이지 완료\n",
      "253페이지 완료\n",
      "254페이지 완료\n",
      "255페이지 완료\n",
      "256페이지 완료\n",
      "257페이지 완료\n",
      "258페이지 완료\n",
      "259페이지 완료\n",
      "260페이지 완료\n",
      "261페이지 완료\n",
      "262페이지 완료\n",
      "263페이지 완료\n",
      "264페이지 완료\n",
      "265페이지 완료\n",
      "266페이지 완료\n",
      "267페이지 완료\n",
      "268페이지 완료\n",
      "269페이지 완료\n",
      "270페이지 완료\n",
      "271페이지 완료\n",
      "272페이지 완료\n",
      "273페이지 완료\n",
      "274페이지 완료\n",
      "275페이지 완료\n",
      "276페이지 완료\n",
      "277페이지 완료\n",
      "278페이지 완료\n",
      "279페이지 완료\n",
      "280페이지 완료\n",
      "281페이지 완료\n",
      "282페이지 완료\n",
      "283페이지 완료\n",
      "284페이지 완료\n",
      "285페이지 완료\n",
      "286페이지 완료\n",
      "287페이지 완료\n",
      "288페이지 완료\n",
      "289페이지 완료\n",
      "290페이지 완료\n",
      "291페이지 완료\n",
      "292페이지 완료\n",
      "293페이지 완료\n",
      "294페이지 완료\n",
      "295페이지 완료\n",
      "296페이지 완료\n",
      "297페이지 완료\n",
      "298페이지 완료\n",
      "299페이지 완료\n",
      "300페이지 완료\n",
      "쉬는중입니다, DDOS차단 방지\n",
      "301페이지 완료\n",
      "302페이지 완료\n",
      "303페이지 완료\n",
      "304페이지 완료\n",
      "305페이지 완료\n",
      "306페이지 완료\n",
      "307페이지 완료\n",
      "308페이지 완료\n",
      "309페이지 완료\n",
      "310페이지 완료\n",
      "311페이지 완료\n",
      "312페이지 완료\n",
      "313페이지 완료\n",
      "314페이지 완료\n",
      "315페이지 완료\n",
      "316페이지 완료\n",
      "317페이지 완료\n",
      "318페이지 완료\n",
      "319페이지 완료\n",
      "320페이지 완료\n",
      "321페이지 완료\n",
      "322페이지 완료\n",
      "323페이지 완료\n",
      "324페이지 완료\n",
      "325페이지 완료\n",
      "326페이지 완료\n",
      "327페이지 완료\n",
      "328페이지 완료\n",
      "329페이지 완료\n",
      "330페이지 완료\n",
      "331페이지 완료\n",
      "332페이지 완료\n",
      "333페이지 완료\n",
      "334페이지 완료\n",
      "335페이지 완료\n",
      "336페이지 완료\n",
      "337페이지 완료\n",
      "338페이지 완료\n",
      "339페이지 완료\n",
      "340페이지 완료\n",
      "341페이지 완료\n",
      "342페이지 완료\n",
      "343페이지 완료\n",
      "344페이지 완료\n",
      "345페이지 완료\n",
      "346페이지 완료\n",
      "347페이지 완료\n",
      "348페이지 완료\n",
      "349페이지 완료\n",
      "350페이지 완료\n",
      "351페이지 완료\n",
      "352페이지 완료\n",
      "353페이지 완료\n",
      "354페이지 완료\n",
      "355페이지 완료\n",
      "356페이지 완료\n",
      "357페이지 완료\n",
      "358페이지 완료\n",
      "359페이지 완료\n",
      "360페이지 완료\n",
      "361페이지 완료\n",
      "362페이지 완료\n",
      "363페이지 완료\n",
      "364페이지 완료\n",
      "365페이지 완료\n",
      "366페이지 완료\n",
      "367페이지 완료\n",
      "368페이지 완료\n",
      "369페이지 완료\n",
      "370페이지 완료\n",
      "371페이지 완료\n",
      "372페이지 완료\n",
      "373페이지 완료\n",
      "374페이지 완료\n",
      "375페이지 완료\n",
      "376페이지 완료\n",
      "377페이지 완료\n",
      "378페이지 완료\n",
      "379페이지 완료\n",
      "380페이지 완료\n",
      "381페이지 완료\n",
      "382페이지 완료\n",
      "383페이지 완료\n",
      "384페이지 완료\n",
      "385페이지 완료\n",
      "386페이지 완료\n",
      "387페이지 완료\n",
      "388페이지 완료\n",
      "389페이지 완료\n",
      "390페이지 완료\n",
      "391페이지 완료\n",
      "392페이지 완료\n",
      "393페이지 완료\n",
      "394페이지 완료\n",
      "395페이지 완료\n",
      "396페이지 완료\n",
      "397페이지 완료\n",
      "398페이지 완료\n",
      "399페이지 완료\n",
      "400페이지 완료\n",
      "쉬는중입니다, DDOS차단 방지\n",
      "401페이지 완료\n",
      "402페이지 완료\n",
      "403페이지 완료\n",
      "404페이지 완료\n",
      "405페이지 완료\n",
      "406페이지 완료\n",
      "407페이지 완료\n",
      "408페이지 완료\n",
      "409페이지 완료\n",
      "410페이지 완료\n",
      "411페이지 완료\n",
      "412페이지 완료\n",
      "413페이지 완료\n",
      "414페이지 완료\n",
      "415페이지 완료\n",
      "416페이지 완료\n",
      "417페이지 완료\n",
      "418페이지 완료\n",
      "419페이지 완료\n",
      "420페이지 완료\n",
      "421페이지 완료\n",
      "422페이지 완료\n",
      "423페이지 완료\n",
      "424페이지 완료\n",
      "425페이지 완료\n",
      "426페이지 완료\n",
      "427페이지 완료\n",
      "428페이지 완료\n",
      "429페이지 완료\n",
      "430페이지 완료\n",
      "431페이지 완료\n",
      "432페이지 완료\n",
      "433페이지 완료\n",
      "434페이지 완료\n",
      "435페이지 완료\n",
      "436페이지 완료\n",
      "437페이지 완료\n",
      "438페이지 완료\n",
      "439페이지 완료\n",
      "440페이지 완료\n",
      "441페이지 완료\n",
      "442페이지 완료\n",
      "443페이지 완료\n",
      "444페이지 완료\n",
      "445페이지 완료\n",
      "446페이지 완료\n",
      "447페이지 완료\n",
      "448페이지 완료\n",
      "449페이지 완료\n",
      "450페이지 완료\n",
      "451페이지 완료\n",
      "452페이지 완료\n",
      "453페이지 완료\n",
      "454페이지 완료\n",
      "455페이지 완료\n",
      "456페이지 완료\n",
      "457페이지 완료\n",
      "458페이지 완료\n",
      "459페이지 완료\n",
      "460페이지 완료\n",
      "461페이지 완료\n",
      "462페이지 완료\n",
      "463페이지 완료\n",
      "464페이지 완료\n",
      "465페이지 완료\n",
      "466페이지 완료\n",
      "467페이지 완료\n",
      "468페이지 완료\n",
      "469페이지 완료\n",
      "470페이지 완료\n",
      "471페이지 완료\n",
      "472페이지 완료\n",
      "473페이지 완료\n",
      "474페이지 완료\n",
      "475페이지 완료\n",
      "476페이지 완료\n",
      "477페이지 완료\n",
      "478페이지 완료\n",
      "479페이지 완료\n",
      "480페이지 완료\n",
      "481페이지 완료\n",
      "482페이지 완료\n",
      "483페이지 완료\n",
      "484페이지 완료\n",
      "485페이지 완료\n",
      "486페이지 완료\n",
      "487페이지 완료\n",
      "488페이지 완료\n",
      "489페이지 완료\n",
      "490페이지 완료\n",
      "491페이지 완료\n",
      "492페이지 완료\n",
      "493페이지 완료\n",
      "494페이지 완료\n",
      "495페이지 완료\n",
      "496페이지 완료\n",
      "497페이지 완료\n",
      "498페이지 완료\n",
      "499페이지 완료\n",
      "500페이지 완료\n",
      "쉬는중입니다, DDOS차단 방지\n",
      "501페이지 완료\n",
      "502페이지 완료\n",
      "503페이지 완료\n",
      "504페이지 완료\n",
      "505페이지 완료\n",
      "506페이지 완료\n",
      "507페이지 완료\n",
      "508페이지 완료\n",
      "509페이지 완료\n",
      "510페이지 완료\n",
      "511페이지 완료\n",
      "512페이지 완료\n",
      "513페이지 완료\n",
      "514페이지 완료\n",
      "515페이지 완료\n",
      "516페이지 완료\n",
      "517페이지 완료\n",
      "518페이지 완료\n",
      "519페이지 완료\n",
      "520페이지 완료\n",
      "521페이지 완료\n",
      "522페이지 완료\n",
      "523페이지 완료\n",
      "524페이지 완료\n",
      "525페이지 완료\n",
      "526페이지 완료\n",
      "527페이지 완료\n",
      "528페이지 완료\n",
      "529페이지 완료\n",
      "530페이지 완료\n",
      "531페이지 완료\n",
      "532페이지 완료\n",
      "533페이지 완료\n",
      "534페이지 완료\n",
      "535페이지 완료\n",
      "536페이지 완료\n",
      "537페이지 완료\n",
      "538페이지 완료\n",
      "539페이지 완료\n",
      "540페이지 완료\n",
      "541페이지 완료\n",
      "542페이지 완료\n",
      "543페이지 완료\n",
      "544페이지 완료\n",
      "545페이지 완료\n",
      "546페이지 완료\n",
      "547페이지 완료\n",
      "548페이지 완료\n",
      "549페이지 완료\n",
      "550페이지 완료\n",
      "551페이지 완료\n",
      "552페이지 완료\n",
      "553페이지 완료\n",
      "554페이지 완료\n",
      "555페이지 완료\n",
      "556페이지 완료\n",
      "557페이지 완료\n",
      "558페이지 완료\n",
      "559페이지 완료\n",
      "560페이지 완료\n",
      "561페이지 완료\n",
      "562페이지 완료\n",
      "563페이지 완료\n",
      "564페이지 완료\n",
      "565페이지 완료\n",
      "566페이지 완료\n",
      "567페이지 완료\n",
      "568페이지 완료\n",
      "569페이지 완료\n",
      "570페이지 완료\n",
      "571페이지 완료\n",
      "572페이지 완료\n",
      "573페이지 완료\n",
      "574페이지 완료\n",
      "575페이지 완료\n",
      "576페이지 완료\n",
      "577페이지 완료\n",
      "578페이지 완료\n",
      "579페이지 완료\n",
      "580페이지 완료\n",
      "581페이지 완료\n",
      "582페이지 완료\n",
      "583페이지 완료\n",
      "584페이지 완료\n",
      "585페이지 완료\n",
      "586페이지 완료\n",
      "587페이지 완료\n",
      "588페이지 완료\n",
      "589페이지 완료\n",
      "590페이지 완료\n",
      "591페이지 완료\n",
      "592페이지 완료\n",
      "593페이지 완료\n",
      "594페이지 완료\n",
      "595페이지 완료\n",
      "596페이지 완료\n",
      "597페이지 완료\n",
      "598페이지 완료\n",
      "599페이지 완료\n",
      "600페이지 완료\n",
      "쉬는중입니다, DDOS차단 방지\n",
      "601페이지 완료\n",
      "602페이지 완료\n",
      "603페이지 완료\n",
      "604페이지 완료\n",
      "605페이지 완료\n",
      "606페이지 완료\n",
      "607페이지 완료\n",
      "608페이지 완료\n",
      "609페이지 완료\n",
      "610페이지 완료\n",
      "611페이지 완료\n",
      "612페이지 완료\n",
      "613페이지 완료\n",
      "614페이지 완료\n",
      "615페이지 완료\n",
      "616페이지 완료\n",
      "617페이지 완료\n",
      "618페이지 완료\n",
      "619페이지 완료\n",
      "620페이지 완료\n",
      "621페이지 완료\n",
      "622페이지 완료\n",
      "623페이지 완료\n",
      "624페이지 완료\n",
      "625페이지 완료\n",
      "626페이지 완료\n",
      "627페이지 완료\n",
      "628페이지 완료\n",
      "629페이지 완료\n",
      "630페이지 완료\n",
      "631페이지 완료\n",
      "632페이지 완료\n",
      "633페이지 완료\n",
      "634페이지 완료\n",
      "635페이지 완료\n",
      "636페이지 완료\n",
      "637페이지 완료\n",
      "638페이지 완료\n",
      "639페이지 완료\n",
      "640페이지 완료\n",
      "641페이지 완료\n",
      "642페이지 완료\n",
      "643페이지 완료\n",
      "644페이지 완료\n",
      "645페이지 완료\n",
      "646페이지 완료\n",
      "647페이지 완료\n",
      "648페이지 완료\n",
      "649페이지 완료\n",
      "650페이지 완료\n",
      "651페이지 완료\n",
      "652페이지 완료\n",
      "653페이지 완료\n",
      "654페이지 완료\n",
      "655페이지 완료\n",
      "656페이지 완료\n",
      "657페이지 완료\n",
      "658페이지 완료\n",
      "659페이지 완료\n",
      "660페이지 완료\n",
      "661페이지 완료\n",
      "662페이지 완료\n",
      "663페이지 완료\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1285\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1286\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1234\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    945\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1402\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m         self.sock = self._create_connection(\n\u001b[0m\u001b[0;32m    918\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    795\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4222b9a3e73e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfor_DDOS_pagenum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mstart_crawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSTART_DATE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEND_DATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfor_DDOS_pagenum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mfor_DDOS_pagenum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"쉬는중입니다, DDOS차단 방지\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a62e71d943dc>\u001b[0m in \u001b[0;36mstart_crawling\u001b[1;34m(keyword, START_DATE, END_DATE, i)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mstart_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTART_DATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mend_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEND_DATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0mget_link_from_news_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_link_from_news_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhURL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSTART_DATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEND_DATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfor_DDOS_pagenum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a62e71d943dc>\u001b[0m in \u001b[0;36mget_link_from_news_title\u001b[1;34m(hURL, START_DATE, END_DATE, for_DDOS_pagenum)\u001b[0m\n\u001b[0;32m    155\u001b[0m                     \u001b[0mDATE_OF_ARTICLE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                     \u001b[0mLINK_OF_ARTICLE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                     \u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                     \u001b[0mFlag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a62e71d943dc>\u001b[0m in \u001b[0;36mget_text\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'User-Agent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0msource_code_from_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_code_from_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"article_txt\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    543\u001b[0m                                   '_open', req)\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1394\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1352\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다>"
     ]
    }
   ],
   "source": [
    "TITLE_OF_ARTICLE = []\n",
    "DATE_OF_ARTICLE = []\n",
    "CONTENT_OF_ARTICLES = []\n",
    "LINK_OF_ARTICLE = []\n",
    "DDOS = True\n",
    "START_DATE = '2020-12-31'\n",
    "END_DATE = '2010-01-01'\n",
    "# 전역변수 설정과 keyword 선언입니다.\n",
    "\n",
    "keyword = quote('인공지능') #또한 인코딩 오류가 나기때문에 인코딩을 위해 quote함수를 사용하였습니다.\n",
    "starttime = time.time()\n",
    "for_DDOS_pagenum=0 # 100페이지마다 쉬기위한 변수이고\n",
    "while True: # while True로 무한반복 해줍니다. (break되기 전가지)\n",
    "    start_crawling(keyword,START_DATE, END_DATE,for_DDOS_pagenum) #크롤링 시작하고\n",
    "    for_DDOS_pagenum += 1 # 100페이지 넘어가면 150초 쉬어줍니다.\n",
    "    print(\"쉬는중입니다, DDOS차단 방지\")\n",
    "    time.sleep(150)\n",
    "    if DDOS == False: # 브레이크 해주는 함수입니다.\n",
    "        break\n",
    "    \n",
    "    \n",
    "runtime = time.time() - starttime\n",
    "\n",
    "print(f'끝! 걸린시간 = {runtime}초')\n",
    "print(f'총 {len(TITLE_OF_ARTICLE)}개의 기사 숫자')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(LINK_OF_ARTICLE, TITLE_OF_ARTICLE, CONTENT_OF_ARTICLES, DATE_OF_ARTICLE)), columns =['LINK','Title', 'Content', 'Date'])\n",
    "df = df[df.Content != \"ERROR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content'] = df['Content'].str.replace(r\"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)\" , '')\n",
    "df['Content'] = df['Content'].str.replace('[', '')\n",
    "df['Content'] = df['Content'].str.replace(']', '')\n",
    "df['Content'] = df['Content'].str.replace(\"'\", \"\")  \n",
    "df['Content'] = df['Content'].str.replace('\"', '')\n",
    "df['Content'] = df['Content'].str.replace(',', '')\n",
    "df['Content'] = df['Content'].str.replace(r'\\\\n', '') \n",
    "df['Content'] = df['Content'].str.replace(r'\\\\r', '')\n",
    "df['Content'] = df['Content'].str.replace(r'\\\\xa0', '')\n",
    "df['Content'] = df['Content'].str.replace('‘', '')\n",
    "df['Content'] = df['Content'].str.replace('’', '')\n",
    "df['Content'] = df['Content'].str.replace('“', '')\n",
    "df['Content'] = df['Content'].str.replace('”', '')\n",
    "df['Content'] = df['Content'].str.replace('//', '')\n",
    "df['Content'] = df['Content'].str.replace('ㆍ', '')\n",
    "df['Content'] = df['Content'].str.replace('  ', '')\n",
    "df['Content'] = df['Content'].str.replace('·', '')\n",
    "df['Content'] = df['Content'].str.replace('…', '')\n",
    "df['Content'] = df['Content'].str.replace('〈br〉', '')\n",
    "df['Content'] = df['Content'].str.replace('「', '')\n",
    "df['Content'] = df['Content'].str.replace('」', '')\n",
    "df['Content'] = df['Content'].str.replace(r'\\\\', '')\n",
    "df['Content'] = df['Content'].str.lstrip()\n",
    "df['Content'] = df['Content'].str.replace(r'\\(([^)]+)\\)','')\n",
    "\n",
    "df['Content'] = df['Content'].str.replace('[.][.]', '.')\n",
    "\n",
    "df['Title'] = df['Title'].str.replace(r'\\[([^)]+)\\]','')\n",
    "df['Title'] = df['Title'].str.replace('‘', '')\n",
    "df['Title'] = df['Title'].str.replace('’', '')\n",
    "df['Title'] = df['Title'].str.replace(',', '')\n",
    "df['Title'] = df['Title'].str.replace('[', '')\n",
    "df['Title'] = df['Title'].str.replace(']', '')\n",
    "df['Title'] = df['Title'].str.replace('…', '')\n",
    "df['Title'] = df['Title'].str.replace('-', '')\n",
    "df['Title'] = df['Title'].str.replace('·', '')\n",
    "df['Title'] = df['Title'].str.replace('“', '')\n",
    "df['Title'] = df['Title'].str.replace('”', '')\n",
    "df['Title'] = df['Title'].str.replace('\"', '')\n",
    "df['Title'] = df['Title'].str.replace('···', '')\n",
    "df['Title'] = df['Title'].str.replace(\"'\", '')\n",
    "df['Title'] = df['Title'].str.replace('?', '')\n",
    "df['Title'] = df['Title'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'동아신문1_{keyword}({START_DATE}~{END_DATE}).csv', encoding = 'utf-8-sig', index_label = False, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ===========================\n",
    "# 150페이지부터 차단이 되길래 100페이지마다 쉬어갔는데도, \n",
    "# 결국 663페이지째에 차단된 모습입니다. \n",
    "# urllib를 사용했음에도 불구하고 시간이 꽤나 오래걸려서 앞의 데이터는 살리고\n",
    "# 663페이지부터 다시 데이터를 모은뒤 취합하는 과정을 거쳤습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_crawling(keyword,START_DATE,END_DATE):#동일합니다.\n",
    "    URL = f'ttps://www.donga.com/news/search?p=1&query={keyword}&check_news=1&more=1&sorting=1&search_date=1&v1=&v2=&range=1'\n",
    "    start_date = datetime.datetime.strptime(START_DATE,'%Y-%m-%d')\n",
    "    end_date = datetime.datetime.strptime(END_DATE,'%Y-%m-%d')\n",
    "    get_link_from_news_title(URL,start_date,end_date)\n",
    "\n",
    "def get_link_from_news_title(hURL,START_DATE,END_DATE):\n",
    "    firstURL = 'h' + hURL\n",
    "    req = urllib.request.Request(firstURL, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'})        \n",
    "    source_code_from_url = urllib.request.urlopen(req)\n",
    "    firstsoup = BeautifulSoup(source_code_from_url, 'lxml', from_encoding='utf-8')\n",
    "    num1 = firstsoup.select('#content > div.searchContWrap > div.searchCont > h2 > span:nth-child(1)')[0].get_text()\n",
    "    num2 = num1.replace('(총 ', '')\n",
    "    num = int(num2.replace(' 건 검색)', ''))\n",
    "    page_num = int(num /15) +1\n",
    "    \n",
    "    Flag = True\n",
    "    for j in range(663,page_num): # <------- \n",
    "        #이부분이 다른데, 앞페이지는 시작부분인 663부터, page_num은 끝까지 지정하였습니다.\n",
    "        #이후는 동일합니다\n",
    "        \n",
    "        \n",
    "        article_number = (j*15) +1\n",
    "        URL = f'ttps://www.donga.com/news/search?p={article_number}&query={keyword}&check_news=1&more=1&sorting=1&search_date=1&v1=&v2=&range=1'\n",
    "        req = urllib.request.Request('h'+URL, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'})        \n",
    "        source_code_from_url = urllib.request.urlopen(req)\n",
    "        soup = BeautifulSoup(source_code_from_url, 'lxml', from_encoding='utf-8')\n",
    "        for i in range(0,len(soup.select('p.tit'))):        \n",
    "            date1 = soup.select(f'#content > div.searchContWrap > div.searchCont > div:nth-child({i+2}) > div.t > p.tit > span')[0]\n",
    "            date2 = date1.get_text()[:10]\n",
    "            try:\n",
    "                date = datetime.datetime.strptime(date2,'%Y-%m-%d')\n",
    "            except:\n",
    "                date = lastdate\n",
    "            lastdate = date            \n",
    "            if START_DATE >= date:\n",
    "                if date >= END_DATE:\n",
    "                    str_date = str(date)[:10]\n",
    "                    title_name = soup.select(f'#content > div.searchContWrap > div.searchCont > div:nth-child({i+2}) > div.t > p.tit > a:nth-child(1)')[0].get_text()\n",
    "                    title_link = soup.select(f'#content > div.searchContWrap > div.searchCont > div:nth-child({i+2}) > div.t > p.tit > a:nth-child(1)')[0]['href']\n",
    "                    TITLE_OF_ARTICLE.append(title_name) \n",
    "                    DATE_OF_ARTICLE.append(str_date)\n",
    "                    LINK_OF_ARTICLE.append(title_link)\n",
    "                    get_text(title_link)\n",
    "                else:\n",
    "                    Flag = False                \n",
    "                    break \n",
    "        \n",
    "        print(f'{j+1}페이지 완료') \n",
    "        \n",
    "        if Flag == False:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bc8cd7505628>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mSTART_DATE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2020-12-31'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mEND_DATE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2010-01-01'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mkeyword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'인공지능'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mstarttime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'quote' is not defined"
     ]
    }
   ],
   "source": [
    "TITLE_OF_ARTICLE = []\n",
    "DATE_OF_ARTICLE = []\n",
    "CONTENT_OF_ARTICLES = []\n",
    "LINK_OF_ARTICLE = []\n",
    "DDOS = True\n",
    "START_DATE = '2020-12-31'\n",
    "END_DATE = '2010-01-01'\n",
    "keyword = quote('인공지능')\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "start_crawling(keyword,START_DATE, END_DATE) \n",
    "\n",
    "    \n",
    "    \n",
    "runtime = time.time() - starttime\n",
    "\n",
    "print(f'끝! 걸린시간 = {runtime}초')\n",
    "print(f'총 {len(TITLE_OF_ARTICLE)}개의 기사 숫자')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(LINK_OF_ARTICLE, TITLE_OF_ARTICLE, CONTENT_OF_ARTICLES, DATE_OF_ARTICLE)), columns =['LINK','Title', 'Content', 'Date'])\n",
    "df = df[df.Content != \"ERROR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content'] = df['Content'].str.replace(r\"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)\" , '')\n",
    "df['Content'] = df['Content'].str.replace('[', '')\n",
    "df['Content'] = df['Content'].str.replace(']', '')\n",
    "df['Content'] = df['Content'].str.replace(\"'\", \"\")  \n",
    "df['Content'] = df['Content'].str.replace('\"', '')\n",
    "df['Content'] = df['Content'].str.replace(',', '')\n",
    "df['Content'] = df['Content'].str.replace(r'\\\\n', '') \n",
    "df['Content'] = df['Content'].str.replace(r'\\\\r', '')\n",
    "df['Content'] = df['Content'].str.replace(r'\\\\xa0', '')\n",
    "df['Content'] = df['Content'].str.replace('‘', '')\n",
    "df['Content'] = df['Content'].str.replace('’', '')\n",
    "df['Content'] = df['Content'].str.replace('“', '')\n",
    "df['Content'] = df['Content'].str.replace('”', '')\n",
    "df['Content'] = df['Content'].str.replace('//', '')\n",
    "df['Content'] = df['Content'].str.replace('ㆍ', '')\n",
    "df['Content'] = df['Content'].str.replace('  ', '')\n",
    "df['Content'] = df['Content'].str.replace('·', '')\n",
    "df['Content'] = df['Content'].str.replace('…', '')\n",
    "df['Content'] = df['Content'].str.replace('〈br〉', '')\n",
    "df['Content'] = df['Content'].str.replace('「', '')\n",
    "df['Content'] = df['Content'].str.replace('」', '')\n",
    "df['Content'] = df['Content'].str.replace(r'\\\\', '')\n",
    "df['Content'] = df['Content'].str.lstrip()\n",
    "df['Content'] = df['Content'].str.replace(r'\\(([^)]+)\\)','')\n",
    "\n",
    "df['Content'] = df['Content'].str.replace('[.][.]', '.')\n",
    "\n",
    "df['Title'] = df['Title'].str.replace(r'\\[([^)]+)\\]','')\n",
    "df['Title'] = df['Title'].str.replace('‘', '')\n",
    "df['Title'] = df['Title'].str.replace('’', '')\n",
    "df['Title'] = df['Title'].str.replace(',', '')\n",
    "df['Title'] = df['Title'].str.replace('[', '')\n",
    "df['Title'] = df['Title'].str.replace(']', '')\n",
    "df['Title'] = df['Title'].str.replace('…', '')\n",
    "df['Title'] = df['Title'].str.replace('-', '')\n",
    "df['Title'] = df['Title'].str.replace('·', '')\n",
    "df['Title'] = df['Title'].str.replace('“', '')\n",
    "df['Title'] = df['Title'].str.replace('”', '')\n",
    "df['Title'] = df['Title'].str.replace('\"', '')\n",
    "df['Title'] = df['Title'].str.replace('···', '')\n",
    "df['Title'] = df['Title'].str.replace(\"'\", '')\n",
    "df['Title'] = df['Title'].str.replace('?', '')\n",
    "df['Title'] = df['Title'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'동아신문2_{keyword}({START_DATE}~{END_DATE}).csv', encoding = 'utf-8-sig', index_label = False, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동아신문1.csv와 동아신문2.csv로 따로 저장한 후,\n",
    "# 잘린부분을 확인한뒤 csv파일 자체에서 통합했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
